{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "posted-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"datasets\\Wonderland.txt\"\n",
    "raw_text = open(filename, \"r\", encoding=\"utf-8\").read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "republican-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sapphire-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "violent-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of text: 144572\n",
      "ttl characters 49\n"
     ]
    }
   ],
   "source": [
    "print(f\"len of text: {n_chars}\")\n",
    "print(f\"ttl characters {n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "egyptian-hudson",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    \n",
    "    data_X.append([char_to_int[char] for char in seq_in])\n",
    "    data_y.append(char_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closing-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"ttl patterns: {n_patterns}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confused-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(data_X, (n_patterns, seq_length, 1))\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "y = utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "square-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pediatric-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    "    )\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unexpected-navigation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1129/1129 [==============================] - 365s 322ms/step - loss: 3.0980\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.02407, saving model to weights-improvement-01-3.0241.hdf5\n",
      "Epoch 2/20\n",
      "1129/1129 [==============================] - 396s 350ms/step - loss: 2.8497\n",
      "\n",
      "Epoch 00002: loss improved from 3.02407 to 2.81985, saving model to weights-improvement-02-2.8198.hdf5\n",
      "Epoch 3/20\n",
      "1129/1129 [==============================] - 386s 342ms/step - loss: 2.7381\n",
      "\n",
      "Epoch 00003: loss improved from 2.81985 to 2.71938, saving model to weights-improvement-03-2.7194.hdf5\n",
      "Epoch 4/20\n",
      "1129/1129 [==============================] - 385s 341ms/step - loss: 2.6614\n",
      "\n",
      "Epoch 00004: loss improved from 2.71938 to 2.64502, saving model to weights-improvement-04-2.6450.hdf5\n",
      "Epoch 5/20\n",
      "1129/1129 [==============================] - 376s 333ms/step - loss: 2.5876\n",
      "\n",
      "Epoch 00005: loss improved from 2.64502 to 2.57673, saving model to weights-improvement-05-2.5767.hdf5\n",
      "Epoch 6/20\n",
      "1129/1129 [==============================] - 367s 325ms/step - loss: 2.5292\n",
      "\n",
      "Epoch 00006: loss improved from 2.57673 to 2.51569, saving model to weights-improvement-06-2.5157.hdf5\n",
      "Epoch 7/20\n",
      "1129/1129 [==============================] - 365s 323ms/step - loss: 2.4727\n",
      "\n",
      "Epoch 00007: loss improved from 2.51569 to 2.46563, saving model to weights-improvement-07-2.4656.hdf5\n",
      "Epoch 8/20\n",
      "1129/1129 [==============================] - 370s 328ms/step - loss: 2.4196\n",
      "\n",
      "Epoch 00008: loss improved from 2.46563 to 2.41640, saving model to weights-improvement-08-2.4164.hdf5\n",
      "Epoch 9/20\n",
      "1129/1129 [==============================] - 407s 360ms/step - loss: 2.3766\n",
      "\n",
      "Epoch 00009: loss improved from 2.41640 to 2.37004, saving model to weights-improvement-09-2.3700.hdf5\n",
      "Epoch 10/20\n",
      "1129/1129 [==============================] - 379s 336ms/step - loss: 2.3300\n",
      "\n",
      "Epoch 00010: loss improved from 2.37004 to 2.32685, saving model to weights-improvement-10-2.3268.hdf5\n",
      "Epoch 11/20\n",
      "1129/1129 [==============================] - 365s 323ms/step - loss: 2.2878\n",
      "\n",
      "Epoch 00011: loss improved from 2.32685 to 2.28876, saving model to weights-improvement-11-2.2888.hdf5\n",
      "Epoch 12/20\n",
      "1129/1129 [==============================] - 362s 321ms/step - loss: 2.2458\n",
      "\n",
      "Epoch 00012: loss improved from 2.28876 to 2.25107, saving model to weights-improvement-12-2.2511.hdf5\n",
      "Epoch 13/20\n",
      "1129/1129 [==============================] - 363s 322ms/step - loss: 2.2131\n",
      "\n",
      "Epoch 00013: loss improved from 2.25107 to 2.21459, saving model to weights-improvement-13-2.2146.hdf5\n",
      "Epoch 14/20\n",
      "1129/1129 [==============================] - 365s 323ms/step - loss: 2.1755\n",
      "\n",
      "Epoch 00014: loss improved from 2.21459 to 2.17882, saving model to weights-improvement-14-2.1788.hdf5\n",
      "Epoch 15/20\n",
      "1129/1129 [==============================] - 363s 322ms/step - loss: 2.1388\n",
      "\n",
      "Epoch 00015: loss improved from 2.17882 to 2.14590, saving model to weights-improvement-15-2.1459.hdf5\n",
      "Epoch 16/20\n",
      "1129/1129 [==============================] - 378s 335ms/step - loss: 2.1101\n",
      "\n",
      "Epoch 00016: loss improved from 2.14590 to 2.11307, saving model to weights-improvement-16-2.1131.hdf5\n",
      "Epoch 17/20\n",
      "1129/1129 [==============================] - 365s 323ms/step - loss: 2.0760\n",
      "\n",
      "Epoch 00017: loss improved from 2.11307 to 2.08272, saving model to weights-improvement-17-2.0827.hdf5\n",
      "Epoch 18/20\n",
      "1129/1129 [==============================] - 365s 323ms/step - loss: 2.0481\n",
      "\n",
      "Epoch 00018: loss improved from 2.08272 to 2.05294, saving model to weights-improvement-18-2.0529.hdf5\n",
      "Epoch 19/20\n",
      "1129/1129 [==============================] - 366s 324ms/step - loss: 2.0100\n",
      "\n",
      "Epoch 00019: loss improved from 2.05294 to 2.02450, saving model to weights-improvement-19-2.0245.hdf5\n",
      "Epoch 20/20\n",
      "1129/1129 [==============================] - 363s 322ms/step - loss: 1.9971\n",
      "\n",
      "Epoch 00020: loss improved from 2.02450 to 2.00349, saving model to weights-improvement-20-2.0035.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23aae18c610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "municipal-croatia",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_lstm_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_lstm_1\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, r\"models/model_lstm_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecological-wrestling",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(\"weights\", \"weights-improvement-20-2.0035.hdf5\")\n",
    "model.load_weights(filename)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "headed-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "strategic-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "ITERS = 100\n",
    "final_line = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "widespread-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    beautiful, beauti—ful soup!”\n",
      "\n",
      "\n",
      "“chorus again!” cried the gryphon, and the mock turtle had just be\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "start = np.random.randint(0, len(data_X) - 1)\n",
    "\n",
    "pattern = data_X[start]\n",
    "\n",
    "print(''.join([int_to_char[value] for value in pattern]))\n",
    "\n",
    "for i in range(ITERS):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    idx = np.argmax(prediction)\n",
    "    result = int_to_char[idx]\n",
    "    \n",
    "    final_line = final_line + result\n",
    "    \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    pattern.append(idx)\n",
    "    pattern = pattern[1: len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "industrial-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lut an in ano drene th the tibte \n",
      "andce wan aniin  the had nutt then the was soi tired sar th the li\n"
     ]
    }
   ],
   "source": [
    "print(final_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-bearing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_venv",
   "language": "python",
   "name": "lstm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
